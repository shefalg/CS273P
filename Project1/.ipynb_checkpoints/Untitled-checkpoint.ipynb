{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f02c88198672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "import sklearn as sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import mltools as ml\n",
    "import h2o\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from __future__ import print_function\n",
    "# h2o.init()\n",
    "\n",
    "train = h2o.import_file(\"X_train.txt\")\n",
    "y=h2o.import_file(\"Y_train.txt\")\n",
    "test = h2o.import_file(\"X_test.txt\")\n",
    "\n",
    "# Identify predictors and response\n",
    "x = train.columns\n",
    "# y = \"response\"\n",
    "# x.remove(y)\n",
    "x = x[0:50000:]\n",
    "y = y[0:50000:]\n",
    "Xva = x[50000:100000:]\n",
    "Yva = Y[50000:100000:]\n",
    "\n",
    "# Number of CV folds (to generate level-one data for stacking)\n",
    "nfolds = 5\n",
    "\n",
    "# There are a few ways to assemble a list of models to stack together:\n",
    "# 1. Train individual models and put them in a list\n",
    "# 2. Train a grid of models\n",
    "# 3. Train several grids of models\n",
    "# Note: All base models must have the same cross-validation folds and\n",
    "# the cross-validated predicted values must be kept.\n",
    "\n",
    "\n",
    "# 1. Generate a 2-model ensemble (GBM + RF)\n",
    "\n",
    "# Train and cross-validate a GBM\n",
    "my_gbm = H2OGradientBoostingEstimator(distribution=\"bernoulli\",\n",
    "                                      ntrees=10,\n",
    "                                      max_depth=3,\n",
    "                                      min_rows=2,\n",
    "                                      learn_rate=0.2,\n",
    "                                      nfolds=nfolds,\n",
    "                                      fold_assignment=\"Modulo\",\n",
    "                                      keep_cross_validation_predictions=True,\n",
    "                                      seed=1)\n",
    "my_gbm.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "\n",
    "# Train and cross-validate a RF\n",
    "my_rf = H2ORandomForestEstimator(ntrees=50,\n",
    "                                 nfolds=nfolds,\n",
    "                                 fold_assignment=\"Modulo\",\n",
    "                                 keep_cross_validation_predictions=True,\n",
    "                                 seed=1)\n",
    "my_rf.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "\n",
    "# Train a stacked ensemble using the GBM and GLM above\n",
    "ensemble = H2OStackedEnsembleEstimator(model_id=\"my_ensemble_binomial\",\n",
    "                                       base_models=[my_gbm, my_rf])\n",
    "ensemble.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# Eval ensemble performance on the test data\n",
    "perf_stack_test = ensemble.model_performance(test)\n",
    "\n",
    "# Compare to base learner performance on the test set\n",
    "perf_gbm_test = my_gbm.model_performance(test)\n",
    "perf_rf_test = my_rf.model_performance(test)\n",
    "baselearner_best_auc_test = max(perf_gbm_test.auc(), perf_rf_test.auc())\n",
    "stack_auc_test = perf_stack_test.auc()\n",
    "print(\"Best Base-learner Test AUC:  {0}\".format(baselearner_best_auc_test))\n",
    "print(\"Ensemble Test AUC:  {0}\".format(stack_auc_test))\n",
    "\n",
    "# Generate predictions on a test set (if neccessary)\n",
    "pred = ensemble.predict(test)\n",
    "\n",
    "\n",
    "# 2. Generate a random grid of models and stack them together\n",
    "\n",
    "# Specify GBM hyperparameters for the grid\n",
    "hyper_params = {\"learn_rate\": [0.01, 0.03],\n",
    "                \"max_depth\": [3, 4, 5, 6, 9],\n",
    "                \"sample_rate\": [0.7, 0.8, 0.9, 1.0],\n",
    "                \"col_sample_rate\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]}\n",
    "search_criteria = {\"strategy\": \"RandomDiscrete\", \"max_models\": 3, \"seed\": 1}\n",
    "# Train the grid\n",
    "grid = H2OGridSearch(model=H2OGradientBoostingEstimator(ntrees=10,\n",
    "                                                        seed=1,\n",
    "                                                        nfolds=nfolds,\n",
    "                                                        fold_assignment=\"Modulo\",\n",
    "                                                        keep_cross_validation_predictions=True),\n",
    "                     hyper_params=hyper_params,\n",
    "                     search_criteria=search_criteria,\n",
    "                     grid_id=\"gbm_grid_binomial\")\n",
    "grid.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# Train a stacked ensemble using the GBM grid\n",
    "ensemble = H2OStackedEnsembleEstimator(model_id=\"my_ensemble_gbm_grid_binomial\",\n",
    "                                       base_models=grid.model_ids)\n",
    "ensemble.train(x=x, y=y, training_frame=train)\n",
    "\n",
    "# Eval ensemble performance on the test data\n",
    "perf_stack_test = ensemble.model_performance(test)\n",
    "\n",
    "# Compare to base learner performance on the test set\n",
    "baselearner_best_auc_test = max([h2o.get_model(model).model_performance(test_data=test).auc() for model in grid.model_ids])\n",
    "stack_auc_test = perf_stack_test.auc()\n",
    "print(\"Best Base-learner Test AUC:  {0}\".format(baselearner_best_auc_test))\n",
    "print(\"Ensemble Test AUC:  {0}\".format(stack_auc_test))\n",
    "\n",
    "YvaHat=ensemble.predict(Xva)\n",
    "print(\"Mse \"+ str(mean_squared_error(YvaHat,Yva)))\n",
    "# Generate predictions on a test set (if neccessary)\n",
    "pred = ensemble.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
